{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Potentials Exercises July 19 \n",
    "## QML package and QM7 learning curves\n",
    "\n",
    "In this exercise we will work with QM7 again, but this time we will focus on learning curves. Learning curves are plots used to show a model's performance as the training set size increases. They gives us information about the generalization error and they can also predict how large a training set we need to get the desired accuracy. To speed up and simplify the work, we will use the QML package for this task. \n",
    "\n",
    "QML is a Python2/3-compatible toolkit for representation learning of properties of molecules and solids. The goal is to provide usable and efficient implementations of concepts such as representations and kernels. QML supplies the building blocks to carry out efficient and accurate machine learning on chemical compounds.\n",
    "\n",
    "Documentation: https://www.qmlcode.org/index.html#<br /> \n",
    "GitHub repository: https://github.com/qmlcode/qml<br /> \n",
    "GPU version: https://github.com/nickjbrowning/QMLightning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import qml\n",
    "import time\n",
    "from qml.kernels import gaussian_kernel\n",
    "from qml.math import cho_solve\n",
    "from qml.representations import get_slatm_mbtypes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect QML Compound\n",
    "QML has `Compound` objects that store all information from xyz files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = qml.Compound(xyz=\"qm7_files/qm7/0001.xyz\")\n",
    "print(mol.coordinates)\n",
    "print(mol.atomtypes)\n",
    "print(mol.nuclear_charges)\n",
    "print(mol.name)\n",
    "print(mol.unit_cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load QM7 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load molecules to Compound class\n",
    "xyzs = sorted(glob(\"qm7_files/qm7/*.xyz\"))\n",
    "mols = [qml.Compound(x) for x in xyzs]\n",
    "# Load energies\n",
    "energies = pd.read_csv('qm7_files/hof_qm7.txt', header=None, sep='\\s', engine='python')\n",
    "energies.columns = ['filename', 'PBE0', 'DFTB']\n",
    "y = energies.PBE0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Coulomb matrix\n",
    "We will start with the Coulomb matrix due to its simplicity. We will use KKR (with rbf kernel) but this time, we will use the QML package. We will use hyperparameters from the previous exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Coulomb matrix for all molecules. It takes few minutes.\n",
    "cm = np.array([np.array(qml.representations.generate_coulomb_matrix(\n",
    "                                    mol.nuclear_charges,                               \n",
    "                                    mol.coordinates,\n",
    "                                    size=23,\n",
    "                                    sorting=\"row-norm\"))\n",
    "       for mol in mols],dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "####YOUR TURN: fill in your optimal alpha and gamma for 'rbf' kernel from previous exercise\n",
    "alpha = \n",
    "gamma = \n",
    "####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning curve is the dependence of the test error (mean absolute error) on the size of the training set. All molecules that are not included in the training set belong to the test set. To plot this dependence, we need to know the MAE for different test set sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired train set sizes\n",
    "train_ratio = [0.004506408, 0.014082524, 0.044500775, 0.14082524, 0.445289396]\n",
    "total_mol = y.shape[0]\n",
    "train_size = [x*total_mol for x in train_ratio]\n",
    "test_error = []\n",
    "\n",
    "for ratio in train_ratio:\n",
    "    # Split data to train and test sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(cm, y, train_size = ratio, test_size = 1 - ratio)\n",
    "\n",
    "    # Calculate kernel matrix\n",
    "    K = gaussian_kernel(X_train, X_train, 1/np.sqrt(2*gamma)\n",
    "\n",
    "    # Add a small lambda to the diagonal of the kernel matrix\n",
    "    K[np.diag_indices_from(K)] += alpha\n",
    "\n",
    "    # Use the built-in Cholesky-decomposition to find c\n",
    "    c = cho_solve(K, Y_train)\n",
    "\n",
    "    # Calculate a kernel matrix between test and training data, using the same gamma\n",
    "    Ks = gaussian_kernel(X_test, X_train, 1/np.sqrt(2*gamma)\n",
    "\n",
    "    # Make the predictions\n",
    "    Y_predicted = np.dot(Ks, c)\n",
    "    \n",
    "    # Calculate mean absolute-error (MAE)\n",
    "    mae = np.mean(np.abs(Y_predicted - Y_test))\n",
    "    \n",
    "    # Calculate training size\n",
    "    size = ratio * total_mol\n",
    "    \n",
    "    test_error.append(mae)\n",
    "    print(\"Training size: %i\\t MAE: %.2f kcal/mol\" % (size, mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the learning curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(train_size, test_error, color=\"red\", ls=\"-\", marker =\"o\", label=r'Coulomb matrix')\n",
    "plt.xlabel('Training set size')\n",
    "plt.ylabel('MAE (kcal/mol)')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should observe linearity, although this may not always be the case. Repeat the training again and observe how the errors and plot change slightly. This comes from splitting the molecules into test and train datasets differently each time. However, not all molecules carry identical information. Therefore we should not take just one model, but always the average of several with different train/test distributions. Implement average over several models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = [0.004506408, 0.014082524, 0.044500775, 0.14082524, 0.445289396]\n",
    "train_size = [x*y.shape[0] for x in train_ratio]\n",
    "test_error = []\n",
    "emsemble = 10\n",
    "\n",
    "for ratio in train_ratio:\n",
    "    sum_mae = 0\n",
    "    size = ratio * total_mol\n",
    "    for x in range(emsemble):\n",
    "        ####################################\n",
    "        ####YOUR TURN: Train KKR model and find MAE\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ####################################\n",
    "        sum_mae = sum_mae + mae\n",
    "    test_error.append(sum_mae/emsemble)\n",
    "    print(\"Training size: %i\\t Averaged MAE: %.2f kcal/mol\" % (size, mae))\n",
    "    \n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(train_size, test_error, color=\"red\", ls=\"-\", marker =\"o\", label=r'Coulomb matrix')\n",
    "plt.xlabel('Training set size')\n",
    "plt.ylabel('MAE (kcal/mol)')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FCHL19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Coulomb matrix, we have demonstrated how a learning curve is constructed. However, due to its simplicity, this descriptor does not achieve excellent results. We now move on to the FCHL19 descriptors, which are one of the best nowadays. \n",
    "\n",
    "Briefly described, the FCHL19 representation is a vector that encodes the atomic environment of an atom in a chemical compound. It consists of a two-body term which encodes radial distributions between the central atoms and neighboring atoms of a given element type. Additionally, the representation contains a three-body term that encodes the mean distances and angles between the atom and neighboring pairs of atoms of given element types. It does not include an explicit one-body term. Please refer to the paper for more details: https://aip.scitation.org/doi/10.1063/1.5126701\n",
    "\n",
    "The higher accuracy is compensated by an increase in computational complexity. Therefore, in this part of the exercise, we will not average models and will train the models only up to 1000 molecules in the training set.\n",
    "\n",
    "Your task is to plot a learning curve for KKR with FCHL19 descriptors for training set ratios of 0.004506408, 0.014082524, 0.044500775, and 0.14082524 without averaging. Compare the time complexity with the Coulomb matrix for an identical size training set. Below we provide an example of how to train the FCHL19 model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate FCHL19 representation for all molecules.\n",
    "fchl = np.array([qml.fchl.generate_representation(mol.coordinates,\n",
    "                                                  mol.nuclear_charges)\n",
    "        for mol in mols],dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.004506408\n",
    "test_ratio = 1 - train_ratio\n",
    "\n",
    "# Split data to train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(fchl, y, train_size = train_ratio, test_size = test_ratio)\n",
    "\n",
    "# Hyperpamateres. You do not need to tune.\n",
    "alpha = 1e-7\n",
    "sigmas = [1.0]\n",
    "\n",
    "start = time.time()\n",
    "# Calculate kernel matrix for train set\n",
    "K = qml.fchl.get_local_kernels(X_train, X_train, sigmas, cut_distance=10.0)[0]\n",
    "\n",
    "# Add a small lambda to the diagonal of the kernel matrix\n",
    "K[np.diag_indices_from(K)] += alpha\n",
    "\n",
    "# Use the built-in Cholesky-decomposition to find c\n",
    "c = cho_solve(K,Y_train)\n",
    "end = time.time()\n",
    "print(\"Training time:\", end-start, \"sec\")\n",
    "\n",
    "start = time.time()\n",
    "# Calculate a kernel matrix between test and training data\n",
    "K_test = qml.fchl.get_local_kernels(X_test, X_train, sigmas, cut_distance=10.0)[0]\n",
    "\n",
    "# Make the predictions\n",
    "Y_pred = np.dot(K_test, c)\n",
    "\n",
    "# Calculate mean absolute-error (MAE):\n",
    "mae = np.mean(np.abs(Y_test - Y_pred))\n",
    "size = train_ratio * total_mol\n",
    "\n",
    "end = time.time()\n",
    "print(\"Prediction time:\", end-start, \"sec\")\n",
    "print(\"Training size: %i\\t MAE: %.2f kcal/mol\" % (size, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "####YOUR TURN: Train KKR model with FCHL19 and get MAE for various training set sizes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "####YOUR TURN: Plot learning curve for KKR model with FCHL19\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "####YOUR TURN: Compare learning curves of the Coulomb Matrix and FCHL19 in the same plot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
